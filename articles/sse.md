# SSE идеален для сценариев, где клиент — пассивный слушатель

# Введение

Когда нужно передавать данные от сервера к клиенту в реальном времени, первое, что приходит в голову — WebSocket. Но что если поток данных односторонний? Что если не нужна сложная инфраструктура и достаточно обычного HTTP?

Server-Sent Events (SSE) — это элегантное решение для задач, где клиент только получает данные: live-уведомления, обновления дашбордов, стриминг логов, мониторинг метрик.

Но как убедиться, что SSE-сервис выдержит нагрузку? Как правильно настроить таймауты, буферизацию и тестирование тысяч одновременных подключений?

В этой статье практическое руководство по созданию полноценного стенда для тестирования SSE, от реализации сервера до симуляции нагрузки.

# SSE

SSE (Server-Sent Events) — это технология, позволяющая серверу автоматически отправлять данные в браузер по установленному HTTP-соединению

1. Данные идут отлько от сервера к клиенту.
2. Работает через втсроенный в браузер JS-интерфейс (EventSource).
3. При обрыве соединения, браузер сам пытается восстановить его.

Когда использовать?

1. Ленты новостей
2. События мониторинга
3. Уведомления о статусе запущенных в фоновом режиме команд
3. Системные уведомления

**Сравнение с WebSockets**

| Характеристика | EventSource (SSE) | WebSockets |
|:---|:---:|:---:|:---:|
| Направление | Только от сервера к клиенту | Двустороннее (дуплекс) |
| Протокол | Обычный HTTP | Свой протокол (ws://) |
| Формат | Только текст (UTF-8) | Текст и бинарные данные |
| Переподключение | Встроено «из коробки» | Нужно реализовывать вручную |
| Лимиты | Ограничение на 6 соединений (в HTTP/1.1) | Практически не ограничено |

**Ограничение браузеров**

При использовании HTTP/1.1 браузеры ограничивают количество SSE-соединений до 6 на домен. Если открыть 7 вкладок с одним и тем же сайтом, последние не заработают. Решение — переход на HTTP/2.

# Персональные и широковещательные уведомления

Для реализации персональных и широковещательных уведомлений через SSE основная логика ложится на бэкенд, так как протокол сам по себе - это просто труба. Ключ к успеху правильное управление списком активных соединений.

## Архитектура

Чтобы N сервисов работали как единое целое, они должны обмениваться сообщениями через общую шину. NATS идеально подходит для этого

- Один сервис публикует сообщение в NATS-канал broadcast. Все N сервисов, подписанные на этот канал, получают его и отправляют своим подключенным клиентам
- Персональное сообщение публикуется в канал user:{userId}. Только тот сервис, к которому в данный момент физически подключен этот пользователь, считает сообщение из Redis и пробросит в SSE-поток.

Логика работы бекенда

Каждый из N инстансов делает следующее:

1. При GET /events:
    - Устанавливает SSE-соединение
    - Cохраняет объект ответа в локальном Map<userId, Response>.
    - Подписывается на канал user:{userId}
2. При старте, подписывается на канал broadcast.
3. При получении сообщения из Redis:
    - Если это broadcast — передает по всем своим локальным клиентам из Map<userId, Response>.
    - Если это user:{userId} — проверяет, есть ли пользователь в его локальной Map. Если есть — отправляет.

Стратегия подписок NATS

- Персональная notifications.user.{userId}
- Широковещательная notifications.broadcast

Использование NATS JetStream превращает обычную рассылку (Fire-and-forget) в полноценную систему доставки с гарантией и очередью. Это решает главную проблему SSE, если клиент моргнул интернетом и переподключился, обычные сообщения за эти 2 секунды пропадут, а JetStream их дошлет.

Схема работы с JetStream

1. В NATS создается стримы notifications.user.* с политикой хранения по времени или количеству.
2. Каждый потребитель запоминает последний доставленный sequenceId


Плюсы

- Горизонтальное масштабирование. Можно легко увеличить число сервисов с 10 до 100
- Отказоустойчивость. Если один инстанс упадет, Nginx перенаправит клиента на другой, клиент переподключится, и сервис снова подпишется на нужные каналы.
- Простота фронтенда. Для JS-кода это всё тот же один URL new EventSource('/events')
- Гибкость тем. Захотим сегментировать пользователей (например, по городам), просто добавим подписку на notifications.city.moscow

Минусы




# Пошаговая реализация

## Шаг 1. Конфигурация проксирования и потоковой передачи

Добавьте эти директивы в блок location, который обрабатывает ваш SSE-путь

```
location /api/sse-notifications {
    proxy_pass http://sse-server;

    # 1. Отключаем буферизацию — самое важное для SSE
    proxy_buffering off;
    proxy_cache off;

    # 2. Настраиваем поддержку долгоживущих соединений
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    # 3. Увеличиваем таймауты, чтобы Nginx не закрывал соединение
    # По умолчанию 60с, для SSE лучше поставить больше (например, 24 часа)
    proxy_read_timeout 86400s;

    # 4. (Опционально) Отключаем chunked encoding, если клиент его не ждет
    chunked_transfer_encoding off;
}
```

- **proxy_buffering off**. Nginx по умолчанию ждет, пока накопится достаточно данных от сервера, прежде чем отправить их клиенту. Для SSE это ломает логику мгновенных уведомлений.
- **proxy_read_timeout**. Если сервер долго не шлет события, Nginx разорвет связь по таймауту. Большое значение позволяет держать соединение открытым сутками.

## Шаг 2.


# Тестирование

```
$ docker-compose up -d --scale ws-server=1 --scale ws-client=1 --scale sse-server=1
```

```
$ curl -N -v http://localhost:8080/sse-notifications
```
